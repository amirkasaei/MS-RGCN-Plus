{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ffb783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/user01/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from skimage import io\n",
    "from PIL import ImageFile\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b645b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE = \"6\"  \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_DEVICE\n",
    "\n",
    "#model_dir = 'model_VPC_Zurich'\n",
    "embedding_layer_name = 'avgpool'\n",
    "model_name = '256_aug_model'\n",
    "magnifications = [10, 20]\n",
    "folds = ['fold1']\n",
    "patch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea67f170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1\n",
      "compiled_with_cuda: 12.1\n",
      "cuda.is_available: False\n",
      "device_count: 1\n",
      "⚠ Running on CPU\n"
     ]
    }
   ],
   "source": [
    "os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)  \n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"compiled_with_cuda:\", torch.version.cuda)\n",
    "print(\"cuda.is_available:\", torch.cuda.is_available())\n",
    "print(\"device_count:\", torch.cuda.device_count())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    except Exception:\n",
    "        print(\"GPU visible but get_device_name failed (continuing).\")\n",
    "else:\n",
    "    print(\"⚠ Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18033d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/output\n",
    "root_patch_dir = '../data/VPC/multiscale_patches_Train/'\n",
    "output_embedding_dir = '../data/VPC/Embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae1190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x_dict):\n",
    "        return {'label': self.model(x_dict['img'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30696385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_device(d, device='cuda'):\n",
    "    return {k: v.to(device) for k, v in d.items()}\n",
    "\n",
    "\n",
    "def directory_maker(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def get_activation_hook(layer_name):\n",
    "    activation = {}\n",
    "\n",
    "    def hook(model, input, output):\n",
    "        activation[layer_name] = output\n",
    "\n",
    "    return activation, hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac19ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, embedding_layer):\n",
    "    model = torchvision.models.resnet18(pretrained=True).cuda()\n",
    "    activation = {}\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        activation[embedding_layer] = output\n",
    "\n",
    "    model.avgpool.register_forward_hook(hook)\n",
    "    model.eval()\n",
    "    return model, activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc933e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patch_embeddings(model, activation, patch_paths, output_path, embedding_layer):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"✅ Already exists: {output_path}\")\n",
    "        return\n",
    "\n",
    "    transform = transforms.ToTensor()\n",
    "    embeddings = {}\n",
    "\n",
    "    for img_path in patch_paths:\n",
    "        if not img_path.endswith('.png'):\n",
    "            continue\n",
    "        try:\n",
    "            img = io.imread(img_path)\n",
    "            if img.shape[2] == 4: img = img[:, :, :3]\n",
    "        except:\n",
    "            print(f\"Failed to read image: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        img_tensor = transform(img).unsqueeze(0).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model(dict_to_device({'img': img_tensor}))\n",
    "        patch_name = os.path.basename(img_path)[:-4]\n",
    "        emb = activation[embedding_layer].squeeze(0).cpu().numpy()\n",
    "        embeddings[patch_name] = emb\n",
    "\n",
    "    directory_maker(os.path.dirname(output_path))\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "    print(f\"✅ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3f35eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_patch_paths(root_dir, magnifications, sizes):\n",
    "    patch_dict = {mag: {} for mag in magnifications}\n",
    "    for core in os.listdir(root_dir):\n",
    "        for size in sizes:\n",
    "            for mag in magnifications:\n",
    "                patch_folder = os.path.join(root_dir, core, str(size), str(mag))\n",
    "                if not os.path.exists(patch_folder): continue\n",
    "                patch_paths = [os.path.join(patch_folder, f) for f in os.listdir(patch_folder) if f.endswith('.png')]\n",
    "                patch_dict[mag][core] = patch_paths\n",
    "    return patch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(pkl_path, metric='cosine', topk=None, save_csv=True):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        emb_dict = pickle.load(f)\n",
    "\n",
    "    patch_names = sorted(emb_dict.keys())\n",
    "    embeddings = np.array([emb_dict[k] for k in patch_names])\n",
    "\n",
    "    if metric == 'cosine':\n",
    "        sim_matrix = cosine_similarity(embeddings)\n",
    "    elif metric == 'l2':\n",
    "        sim_matrix = -np.linalg.norm(embeddings[:, None] - embeddings[None, :], axis=-1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported metric\")\n",
    "\n",
    "    similarity_list = []\n",
    "    for i, name_i in enumerate(patch_names):\n",
    "        sims = sim_matrix[i]\n",
    "        indices = np.argsort(-sims)  # descending\n",
    "        for j in indices:\n",
    "            if i == j:\n",
    "                continue  # skip self-similarity\n",
    "            if topk and len(similarity_list) >= topk * len(patch_names):\n",
    "                break\n",
    "            name_j = patch_names[j]\n",
    "            similarity_list.append((name_i, name_j, float(sims[j])))\n",
    "\n",
    "    if save_csv:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(similarity_list, columns=['patch_i', 'patch_j', 'similarity'])\n",
    "        out_path = pkl_path.replace('.pkl', f'_{metric}_similarity_pairs.csv')\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "    return similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_embedding_pipeline():\n",
    "    patch_dict = collect_patch_paths(root_patch_dir, magnifications, [patch_size])\n",
    "\n",
    "    for fold in folds:\n",
    "        for mag in magnifications:\n",
    "            # Load ImageNet-pretrained ResNet18 with forward hook\n",
    "            model, activation = load_model(model_name, embedding_layer_name)\n",
    "\n",
    "            for core_name, patch_list in patch_dict[mag].items():\n",
    "                out_pkl = os.path.join(output_embedding_dir, fold, core_name, str(patch_size), str(mag),\n",
    "                                       f'{model_name}_{embedding_layer_name}.pkl')\n",
    "                save_patch_embeddings(model, activation, patch_list, out_pkl, embedding_layer_name)\n",
    "\n",
    "                # Optional: generate similarity \n",
    "                compute_similarity(out_pkl, metric='cosine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d592801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user01/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mrun_embedding_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mrun_embedding_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m folds:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mag \u001b[38;5;129;01min\u001b[39;00m magnifications:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Load ImageNet-pretrained ResNet18 with forward hook\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m         model, activation \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_layer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m core_name, patch_list \u001b[38;5;129;01min\u001b[39;00m patch_dict[mag]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m             out_pkl \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_embedding_dir, fold, core_name, \u001b[38;5;28mstr\u001b[39m(patch_size), \u001b[38;5;28mstr\u001b[39m(mag),\n\u001b[1;32m     11\u001b[0m                                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_layer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, embedding_layer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_name, embedding_layer):\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     activation \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhook\u001b[39m(module, \u001b[38;5;28minput\u001b[39m, output):\n",
      "File \u001b[0;32m~/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torch/nn/modules/module.py:916\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    900\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torch/nn/modules/module.py:916\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    900\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torch/cuda/__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_embedding_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4b6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.8.5 msrgcn)",
   "language": "python",
   "name": "msrgcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
