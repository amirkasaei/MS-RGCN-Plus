{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabe94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/user01/miniconda3/envs/msrgcn/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import io\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "batch_size = 8\n",
    "magnifications = [10, 20]         # e.g., [10, 20, 40]\n",
    "patch_size = 512\n",
    "folds = ['fold1']\n",
    "\n",
    "ROOT_DIR = '../data/VPC/multiscale_patches_Train/'      # your input root \n",
    "EMB_ROOT = '../data/VPC/embeddings_paper_style/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a85414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1\n",
      "compiled_with_cuda: 12.1\n",
      "cuda.is_available: True\n",
      "device_count: 1\n",
      "Using GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"compiled_with_cuda:\", torch.version.cuda)\n",
    "print(\"cuda.is_available:\", torch.cuda.is_available())\n",
    "print(\"device_count:\", torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    except Exception:\n",
    "        pass\n",
    "else:\n",
    "    print(\"⚠ Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831bd5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_TO = 256          # paper uses 256×256 input to ResNet\n",
    "EMBED_LAYER = 'avgpool'  # layer before FC\n",
    "_to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63dc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_maker(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
    "\n",
    "def build_index(root_dir):\n",
    "    \"\"\"\n",
    "    Build a dict: { (core, size, mag): [img_paths...] } assuming tree:\n",
    "      root_dir/<core>/<size>/<mag>/*.png\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    if not os.path.isdir(root_dir):\n",
    "        raise RuntimeError(f\"ROOT_DIR does not exist: {root_dir}\")\n",
    "    for core in sorted(os.listdir(root_dir)):\n",
    "        core_dir = os.path.join(root_dir, core)\n",
    "        if not os.path.isdir(core_dir): continue\n",
    "        for size in sorted(os.listdir(core_dir)):\n",
    "            size_dir = os.path.join(core_dir, size)\n",
    "            if not os.path.isdir(size_dir): continue\n",
    "            for mag in sorted(os.listdir(size_dir)):\n",
    "                mag_dir = os.path.join(size_dir, mag)\n",
    "                if not os.path.isdir(mag_dir): continue\n",
    "                imgs = [os.path.join(mag_dir, f) for f in os.listdir(mag_dir) if f.lower().endswith('.png')]\n",
    "                if imgs:\n",
    "                    index[(core, size, mag)] = sorted(imgs)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee8bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet18_imagenet(num_classes=6):\n",
    "    weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "    model = torchvision.models.resnet18(weights=weights)\n",
    "    model.fc = nn.Linear(512, num_classes, bias=True)  # FC not used; embeddings come from avgpool\n",
    "    return model.to(device).eval()\n",
    "\n",
    "def register_avgpool_hook(model, layer_name=EMBED_LAYER):\n",
    "    activation = {}\n",
    "    def _hook(_, __, output):\n",
    "        activation[layer_name] = output\n",
    "    handle = dict(model.named_modules())[layer_name].register_forward_hook(_hook)\n",
    "    return activation, handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e988424",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_group_embeddings(model, img_paths, target_dir, model_tag='imagenet', layer_name=EMBED_LAYER):\n",
    "    \"\"\"\n",
    "    Save one dict pkl per (core, size, mag):\n",
    "      target_dir/<model_tag>_<layer_name>.pkl  => { \"<basename>\": np.float32[512] }\n",
    "    \"\"\"\n",
    "    directory_maker(target_dir)\n",
    "    out_pkl = os.path.join(target_dir, f\"{model_tag}_{layer_name}.pkl\")\n",
    "    if os.path.exists(out_pkl):\n",
    "        return\n",
    "\n",
    "    activation, handle = register_avgpool_hook(model, layer_name)\n",
    "    emb_dict = {}\n",
    "\n",
    "    for p in img_paths:\n",
    "        try:\n",
    "            img = io.imread(p)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip read error: {p} ({e})\"); continue\n",
    "\n",
    "        # ensure 3 channels\n",
    "        if img.ndim == 2:\n",
    "            img = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
    "        if img.shape[2] == 4:\n",
    "            img = img[:, :, :3]\n",
    "\n",
    "        # resize to 256x256\n",
    "        img = cv.resize(img, (RESIZE_TO, RESIZE_TO), interpolation=cv.INTER_CUBIC)\n",
    "        tens = _to_tensor(img).unsqueeze(0).to(device)   # [1,3,256,256]\n",
    "\n",
    "        _ = model(tens)                                  # forward triggers hook\n",
    "        out = activation[layer_name]                     # [1,512,1,1] or [1,512]\n",
    "        vec = torch.flatten(out, 1).squeeze(0)           # [512]\n",
    "        emb_dict[os.path.basename(p)[:-4]] = vec.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "    handle.remove()\n",
    "    with open(out_pkl, 'wb') as f:\n",
    "        pickle.dump(emb_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26a432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1) index dataset tree\n",
    "    groups = build_index(ROOT_DIR)\n",
    "    if not groups:\n",
    "        print(f\"No <core>/<size>/<mag> groups found under: {ROOT_DIR}\")\n",
    "        return\n",
    "    print(f\"Found {len(groups)} groups (core/size/mag).\")\n",
    "\n",
    "    # 2) load model (ImageNet-pretrained ResNet18)\n",
    "    model = load_resnet18_imagenet()\n",
    "    print(\"Model device:\", next(model.parameters()).device)\n",
    "\n",
    "    # 3) per-group extraction & save\n",
    "    count = 0\n",
    "    for (core, size, mag), img_paths in groups.items():\n",
    "        target_dir = os.path.join(EMB_ROOT, core, str(size), str(mag))\n",
    "        save_group_embeddings(model, img_paths, target_dir, model_tag='imagenet', layer_name=EMBED_LAYER)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"Saved embeddings for {count} groups...\")\n",
    "\n",
    "    print(\"Done. Embeddings saved under:\", EMB_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73dc6a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 732 groups (core/size/mag).\n",
      "Model device: cuda:0\n",
      "Saved embeddings for 100 groups...\n",
      "Saved embeddings for 200 groups...\n",
      "Saved embeddings for 300 groups...\n",
      "Saved embeddings for 400 groups...\n",
      "Saved embeddings for 500 groups...\n",
      "Saved embeddings for 600 groups...\n",
      "Saved embeddings for 700 groups...\n",
      "Done. Embeddings saved under: ../data/VPC/embeddings_paper_style/\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6b8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.8.5 msrgcn)",
   "language": "python",
   "name": "msrgcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
