{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1029d9dc",
   "metadata": {},
   "source": [
    "### Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf2f97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "from pathlib import Path\n",
    "import os, re, csv, numpy as np\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# --- Paths & constants (edit these) ---\n",
    "PATCH_ROOT = Path(\"/home/user01/MS-RGCN-Plus/data/VPC/multiscale_patches_Train\")\n",
    "MAP_DIRS = [\n",
    "    Path(\"/home/user01/MS-RGCN-Plus/data/VPC/Maps/Maps1_T\"),\n",
    "    Path(\"/home/user01/MS-RGCN-Plus/data/VPC/Maps/Maps2_T\"),\n",
    "    Path(\"/home/user01/MS-RGCN-Plus/data/VPC/Maps/Maps3_T\"),\n",
    "    Path(\"/home/user01/MS-RGCN-Plus/data/VPC/Maps/Maps4_T\"),\n",
    "    Path(\"/home/user01/MS-RGCN-Plus/data/VPC/Maps/Maps5_T\"),\n",
    "    Path(\"/home/user01/MS-RGCN-Plus/data/VPC/Maps/Maps6_T\"),\n",
    "]\n",
    "\n",
    "MASK_BASENAME = \"{scid}_classimg_nonconvex.png\"\n",
    "OUT_CSV = \"/home/user01/MS-RGCN-Plus/data/VPC/patch_labels_majority.csv\"\n",
    "\n",
    "BACKGROUND_VALUES = {255}\n",
    "PATCH_SIZE = 512\n",
    "MAGS = (10, 20, 40)\n",
    "# --- Remap (dataset class ids -> training class ids) ---\n",
    "# Your mapping:\n",
    "#  '1'->0, '3'->1, '4'->2, '5'->3, '0'->4, '6'->5\n",
    "MAP_VPC = {'1': 0, '3': 1, '4': 2, '5': 3, '0': 4, '6': 5}\n",
    "\n",
    "# Target number of classes (after remap)\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# Maximum original class id that might appear in masks (because of '6' in the mapping)\n",
    "NUM_CLASSES_ORIG = max(int(k) for k in MAP_VPC.keys()) + 1  # -> 7\n",
    "\n",
    "\n",
    "# Set this if your masks are RGB instead of single-channel ints\n",
    "COLOR_TO_CLASS = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e2771",
   "metadata": {},
   "source": [
    "### Helpers for Path Parsing & Mask Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a544b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Regex parsers for slide/core and coordinates ---\n",
    "slide_core_re = re.compile(r\"slide(\\d{3})_core(\\d{3})\", re.IGNORECASE)\n",
    "xy_re = re.compile(r'(?P<x>\\d+)_(?P<y>\\d+)\\.png$', re.IGNORECASE)\n",
    "\n",
    "def slide_core_id_from_path(p: str) -> str:\n",
    "    m = slide_core_re.search(p)\n",
    "    if not m:\n",
    "        raise ValueError(f\"slide/core id not found in: {p}\")\n",
    "    return f\"slide{m.group(1)}_core{m.group(2)}\"\n",
    "\n",
    "def coords_from_name(name: str):\n",
    "    m = xy_re.search(name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"cannot parse coords from {name}\")\n",
    "    return int(m.group('x')), int(m.group('y'))\n",
    "\n",
    "def find_annotator_masks_for_core(scid: str):\n",
    "    name = MASK_BASENAME.format(scid=scid)\n",
    "    return [root / name for root in MAP_DIRS if (root / name).exists()]\n",
    "\n",
    "def mask_to_ids(arr):\n",
    "    if arr.ndim == 2:\n",
    "        return arr\n",
    "    if arr.ndim == 3 and COLOR_TO_CLASS is not None:\n",
    "        h, w, _ = arr.shape\n",
    "        out = np.full((h, w), 255, dtype=np.uint8)\n",
    "        rgb = arr.reshape(-1, 3)\n",
    "        out_flat = out.reshape(-1)\n",
    "        lut = {(r<<16)+(g<<8)+b: c for (r,g,b), c in COLOR_TO_CLASS.items()}\n",
    "        keys = (rgb[:,0].astype(np.int64)<<16) + (rgb[:,1].astype(np.int64)<<8) + rgb[:,2].astype(np.int64)\n",
    "        unique_keys, inv = np.unique(keys, return_inverse=True)\n",
    "        map_vals = np.full(unique_keys.shape, 255, dtype=np.uint16)\n",
    "        for i, k in enumerate(unique_keys):\n",
    "            if k in lut:\n",
    "                map_vals[i] = lut[k]\n",
    "        out_flat[:] = map_vals[inv]\n",
    "        return out\n",
    "    raise ValueError(\"Mask appears RGB but COLOR_TO_CLASS is None.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d6854",
   "metadata": {},
   "source": [
    "### Histogram & Patch Label Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47c2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_hist(arr, num_classes=NUM_CLASSES_ORIG, ignore=BACKGROUND_VALUES):\n",
    "    vals, counts = np.unique(arr, return_counts=True)\n",
    "    h = np.zeros(num_classes, dtype=np.float64)  # original-id histogram\n",
    "    for v, c in zip(vals, counts):\n",
    "        if v in ignore:\n",
    "            continue\n",
    "        if 0 <= v < num_classes:\n",
    "            h[v] += c\n",
    "    s = h.sum()\n",
    "    if s > 0:\n",
    "        h /= s\n",
    "    return h  # original-id probs\n",
    "\n",
    "\n",
    "def patch_label_probs_from_maps(patch_path: str):\n",
    "    scid = slide_core_id_from_path(patch_path)\n",
    "    x, y = coords_from_name(os.path.basename(patch_path))\n",
    "    expert_masks = find_annotator_masks_for_core(scid)\n",
    "    if len(expert_masks) == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    acc_orig = np.zeros(NUM_CLASSES_ORIG, dtype=np.float64)\n",
    "    used = 0\n",
    "    for mp in expert_masks:\n",
    "        m = io.imread(str(mp))\n",
    "        m = mask_to_ids(m)\n",
    "        crop = m[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "        if crop.shape[:2] != (PATCH_SIZE, PATCH_SIZE):\n",
    "            continue\n",
    "        h_orig = valid_hist(crop, num_classes=NUM_CLASSES_ORIG)\n",
    "        if h_orig.sum() > 0:\n",
    "            acc_orig += h_orig\n",
    "            used += 1\n",
    "\n",
    "    if used == 0:\n",
    "        return None, None, 0\n",
    "\n",
    "    # average across experts in ORIGINAL space\n",
    "    probs_orig = acc_orig / used\n",
    "\n",
    "    # remap to your target class order\n",
    "    probs_tgt = np.zeros(NUM_CLASSES, dtype=np.float64)\n",
    "    for orig_id in range(NUM_CLASSES_ORIG):\n",
    "        key = str(orig_id)\n",
    "        if key in MAP_VPC:\n",
    "            probs_tgt[MAP_VPC[key]] += probs_orig[orig_id]\n",
    "\n",
    "    # hard label after remap (tie → higher target id)\n",
    "    hard = int(np.flatnonzero(probs_tgt == probs_tgt.max()).max())\n",
    "    return probs_tgt, hard, used\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0e52a",
   "metadata": {},
   "source": [
    "### Crawling Patches & Building the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8f78b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_patches(root=PATCH_ROOT, mags=MAGS):\n",
    "    for slide_dir in sorted(root.glob(\"slide*_core*\")):\n",
    "        for mag in mags:\n",
    "            leaf = slide_dir / \"512\" / str(mag)\n",
    "            if not leaf.exists():\n",
    "                continue\n",
    "            for p in sorted(leaf.glob(\"*.png\")):\n",
    "                yield str(p)\n",
    "\n",
    "def build_csv(out_csv=OUT_CSV):\n",
    "    import tqdm\n",
    "    rows = []\n",
    "    all_patches = list(iter_patches(PATCH_ROOT, MAGS))\n",
    "    for p in tqdm.tqdm(all_patches, total=len(all_patches), desc=\"Labeling patches\"):\n",
    "        probs, hard, used = patch_label_probs_from_maps(p)\n",
    "        if probs is None:\n",
    "            continue\n",
    "        rows.append([p, used, hard] + list(probs.astype(np.float32)))\n",
    "\n",
    "    Path(out_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_csv, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        header = [\"path\", \"n_experts_used\", \"hard_label\"] + [f\"p{c}\" for c in range(NUM_CLASSES)]\n",
    "        w.writerow(header)\n",
    "        w.writerows(rows)\n",
    "    print(f\"[OK] Wrote {len(rows)} rows to {out_csv}\")\n",
    "    return out_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233edee",
   "metadata": {},
   "source": [
    "### GPU‑accelerated labeling (per‑core caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceef9e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Labeling device:\", DEVICE)\n",
    "\n",
    "def _bucket_patches_by_core(patch_paths):\n",
    "    \"\"\"Group patch paths by slide_core id and cache their (x,y).\"\"\"\n",
    "    buckets = defaultdict(list)\n",
    "    for p in patch_paths:\n",
    "        scid = slide_core_id_from_path(p)     # 'slideNNN_coreMMM'\n",
    "        x, y = coords_from_name(os.path.basename(p))\n",
    "        buckets[scid].append((p, x, y))\n",
    "    # keep deterministic order\n",
    "    for k in buckets:\n",
    "        buckets[k].sort(key=lambda t: (t[2], t[1]))  # sort by y,x\n",
    "    return buckets\n",
    "\n",
    "def _load_masks_for_core_to_device(scid):\n",
    "    \"\"\"Load all available expert masks for this core, return tensor [E,H,W] on DEVICE.\"\"\"\n",
    "    paths = find_annotator_masks_for_core(scid)\n",
    "    if len(paths) == 0:\n",
    "        return None, 0\n",
    "    arrs = []\n",
    "    for mp in paths:\n",
    "        m = io.imread(str(mp))\n",
    "        m = mask_to_ids(m)    # -> uint8 single-channel, classes 0..NUM_CLASSES-1 or 255 background\n",
    "        arrs.append(m)\n",
    "    # stack -> [E,H,W]\n",
    "    m_np = np.stack(arrs, axis=0)\n",
    "    m_t = torch.from_numpy(m_np).to(DEVICE, non_blocking=True)\n",
    "    return m_t, m_np.shape[0]\n",
    "\n",
    "def _patch_probs_from_masks_gpu(masks_EHW, x, y):\n",
    "    \"\"\"\n",
    "    masks_EHW: torch uint8 [E,H,W] on DEVICE\n",
    "    returns probs[NUM_CLASSES], hard_label, used_experts\n",
    "    \"\"\"\n",
    "    E, H, W = masks_EHW.shape\n",
    "    if y+PATCH_SIZE > H or x+PATCH_SIZE > W:\n",
    "        return None, None, 0\n",
    "\n",
    "    crop = masks_EHW[:, y:y+PATCH_SIZE, x:x+PATCH_SIZE]            # [E,Ps,Ps]\n",
    "    valid = (crop != 255)                                          # background mask\n",
    "    if not valid.any():\n",
    "        return None, None, 0\n",
    "\n",
    "    # one-hot over classes 0..NUM_CLASSES-1 (ignore where invalid)\n",
    "    # clamp to avoid accidental 255 indexing\n",
    "    crop_clamped = torch.clamp(crop.long(), 0, NUM_CLASSES_ORIG-1)\n",
    "    oh = F.one_hot(crop_clamped, num_classes=NUM_CLASSES_ORIG)  # [E,Ps,Ps,C_orig]\n",
    "    oh = oh.permute(0,3,1,2).float()                               # [E,C,Ps,Ps]\n",
    "    oh = oh * valid.unsqueeze(1).float()                            # zero out background\n",
    "\n",
    "    # per-expert class counts\n",
    "    counts_EC = oh.sum(dim=(2,3))                                  # [E,C]\n",
    "\n",
    "    # normalize per expert to probs; filter experts that had any valid pixel\n",
    "    pix_per_exp = counts_EC.sum(dim=1)                             # [E]\n",
    "    good = pix_per_exp > 0\n",
    "    if not torch.any(good):\n",
    "        return None, None, 0\n",
    "    probs_EC = torch.zeros_like(counts_EC, dtype=torch.float32)\n",
    "    probs_EC[good] = counts_EC[good] / pix_per_exp[good].unsqueeze(1)\n",
    "\n",
    "    # average across used experts → final probs\n",
    "    used = int(good.sum().item())\n",
    "    probs_orig = probs_EC[good].mean(dim=0)  # [C_orig]\n",
    "\n",
    "    # remap to target order\n",
    "    probs_tgt = torch.zeros(NUM_CLASSES, device=probs_orig.device, dtype=probs_orig.dtype)\n",
    "    for key, tgt in MAP_VPC.items():\n",
    "        orig = int(key)\n",
    "        if orig < probs_orig.numel():\n",
    "            probs_tgt[tgt] += probs_orig[orig]\n",
    "\n",
    "    # tie → higher target id\n",
    "    hard = int(torch.nonzero(probs_tgt == probs_tgt.max(), as_tuple=False).max().item())\n",
    "    return probs_tgt.detach().cpu().numpy(), hard, used\n",
    "\n",
    "def build_csv_gpu(out_csv=OUT_CSV, mags=MAGS, flush_cuda_each_core=True, max_cores=None):\n",
    "    \"\"\"\n",
    "    Faster CSV builder (with tqdm):\n",
    "      - buckets patches per core\n",
    "      - loads each core's masks once to GPU\n",
    "      - computes per-patch soft labels on GPU\n",
    "      - optionally limit the number of cores via max_cores\n",
    "      - progress bars for cores and per-core patches\n",
    "    \"\"\"\n",
    "    # gather all patch paths\n",
    "    all_patches = list(iter_patches(PATCH_ROOT, mags=mags))\n",
    "    buckets = _bucket_patches_by_core(all_patches)\n",
    "\n",
    "    # keep only a subset of cores (deterministic order)\n",
    "    core_ids = sorted(buckets.keys())\n",
    "    if max_cores is not None:\n",
    "        core_ids = core_ids[:int(max_cores)]\n",
    "\n",
    "    print(f\"Cores to process: {len(core_ids)}\")\n",
    "\n",
    "    rows = []\n",
    "    processed = 0\n",
    "\n",
    "    # ---- tqdm over cores ----\n",
    "    for scid in tqdm(core_ids, desc=\"Processing cores\", unit=\"core\"):\n",
    "        items = buckets[scid]\n",
    "\n",
    "        masks_EHW, E = _load_masks_for_core_to_device(scid)\n",
    "        if masks_EHW is None:\n",
    "            # no masks for this core; skip its patches\n",
    "            processed += len(items)\n",
    "            continue\n",
    "\n",
    "        # ---- tqdm over patches within this core ----\n",
    "        for (ppath, x, y) in tqdm(items, desc=f\"{scid} patches\", unit=\"patch\", leave=False):\n",
    "            probs, hard, used = _patch_probs_from_masks_gpu(masks_EHW, x, y)\n",
    "            if probs is None:\n",
    "                continue\n",
    "            rows.append([ppath, used, hard] + [float(p) for p in probs])\n",
    "            processed += 1\n",
    "\n",
    "        # free GPU memory per core\n",
    "        del masks_EHW\n",
    "        if DEVICE == \"cuda\" and flush_cuda_each_core:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    Path(out_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_csv, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        header = [\"path\", \"n_experts_used\", \"hard_label\"] + [f\"p{c}\" for c in range(NUM_CLASSES)]\n",
    "        w.writerow(header)\n",
    "        w.writerows(rows)\n",
    "\n",
    "    print(f\"[OK] Wrote {len(rows)} labeled patches to {out_csv}\")\n",
    "    return out_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ea36b",
   "metadata": {},
   "source": [
    "### Dataset Class with Soft or Hard Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d1fb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchCSVWithSoftLabels(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, target_kind=\"soft\"):\n",
    "        self.items = []\n",
    "        with open(csv_file) as f:\n",
    "            r = csv.DictReader(f)\n",
    "            for row in r:\n",
    "                used = int(row[\"n_experts_used\"])\n",
    "                if used == 0:\n",
    "                    continue\n",
    "                p = row[\"path\"]\n",
    "                probs = torch.tensor([float(row[f\"p{c}\"]) for c in range(NUM_CLASSES)], dtype=torch.float32)\n",
    "                hard  = int(row[\"hard_label\"])\n",
    "                self.items.append((p, probs, hard))\n",
    "        self.tf = transform or T.ToTensor()\n",
    "        assert target_kind in (\"soft\",\"hard\")\n",
    "        self.target_kind = target_kind\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        p, probs, hard = self.items[i]\n",
    "        from PIL import Image\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        img = self.tf(img)\n",
    "        if self.target_kind == \"soft\":\n",
    "            y = probs\n",
    "        else:\n",
    "            y = torch.tensor(hard, dtype=torch.long)\n",
    "        return {\"img\": img, \"label\": y, \"path\": p}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2ed79",
   "metadata": {},
   "source": [
    "### Run Label Building & Quick Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e46a61da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores to process: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cores: 100%|██████████| 244/244 [03:20<00:00,  1.22core/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote 71244 labeled patches to /home/user01/MS-RGCN-Plus/data/VPC/patch_labels_majority.csv\n",
      "Train samples: 71244\n",
      "Example shapes: torch.Size([3, 512, 512]) torch.Size([6]) /home/user01/MS-RGCN-Plus/data/VPC/multiscale_patches_Train/slide001_core003/512/10/0_0.png\n"
     ]
    }
   ],
   "source": [
    "# Build CSV\n",
    "# csv_path = build_csv(OUT_CSV)\n",
    "csv_path = build_csv_gpu(OUT_CSV, mags=(10,20,40))\n",
    "# csv_path = build_csv_gpu(OUT_CSV, mags=(40,))\n",
    "\n",
    "# Example usage\n",
    "AUG = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    # T.RandomVerticalFlip(),\n",
    "    # T.RandomHorizontalFlip(),\n",
    "    # T.RandomRotation([0,90,180,270]),\n",
    "])\n",
    "train_ds = PatchCSVWithSoftLabels(csv_path, transform=AUG, target_kind=\"soft\")\n",
    "val_ds   = PatchCSVWithSoftLabels(csv_path, transform=T.ToTensor(), target_kind=\"soft\")\n",
    "\n",
    "print(\"Train samples:\", len(train_ds))\n",
    "if len(train_ds) > 0:\n",
    "    s = train_ds[0]\n",
    "    print(\"Example shapes:\", s[\"img\"].shape, s[\"label\"].shape, s[\"path\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd88d3e",
   "metadata": {},
   "source": [
    "### 📄 Patch Labels CSV – Column Description (with `map_vpc` Applied)\n",
    "\n",
    "This CSV contains **patch-level labels** generated by majority voting across expert annotation masks, then **remapped** to match the classification scheme used in the ResNet training code.\n",
    "\n",
    "| Column Name        | Type     | Description |\n",
    "|--------------------|----------|-------------|\n",
    "| **path**           | `str`    | Absolute path to the patch image file (e.g., `/home/user01/MS-RGCN-Plus/data/VPC/multiscale_patches_Train/slide001_core003/512/40/0_1024.png`). Identifies the specific patch at a given magnification. |\n",
    "| **n_experts_used** | `int`    | Number of pathologists’ maps that were successfully loaded for this core/patch and used in voting. This may be less than the total available maps if some masks are missing. |\n",
    "| **hard_label**     | `int`    | **Remapped class index** based on `map_vpc` (`{'1':0, '3':1, '4':2, '5':3, '0':4, '6':5}`). This is the integer class ID you should use for training. It corresponds to Gleason grades but in the custom index order used by your model. |\n",
    "| **p0 ... p5**      | `float`  | Soft-label probabilities for each remapped class index (`0`–`5`). These are normalized to sum to 1.0 and represent the proportion of experts voting for each class. |\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔄 **Mapping Logic**\n",
    "The `map_vpc` remap converts original Gleason grade labels into model-specific class IDs:\n",
    "\n",
    "| Original Gleason Grade | Mapped Class ID |\n",
    "|------------------------|-----------------|\n",
    "| 1                      | 0 |\n",
    "| 3                      | 1 |\n",
    "| 4                      | 2 |\n",
    "| 5                      | 3 |\n",
    "| 0 (normal)             | 4 |\n",
    "| 6                      | 5 |\n",
    "\n",
    "> Any missing Gleason grades in the dataset will simply not appear in the CSV.\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ **Usage Notes**\n",
    "- `hard_label` is the **final class ID** you should feed into your training pipeline.\n",
    "- `p0...p5` can be used for **soft-label training** or as confidence scores.\n",
    "- If you filter patches by magnification, ensure you only train with patches matching your intended `magnification` value.\n",
    "- The CSV can be regenerated at any time by running the GPU CSV builder with `map_vpc` applied inside the loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>n_experts_used</th>\n",
       "      <th>hard_label</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/user01/MS-RGCN-Plus/data/VPC/multiscale_...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/user01/MS-RGCN-Plus/data/VPC/multiscale_...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/user01/MS-RGCN-Plus/data/VPC/multiscale_...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/user01/MS-RGCN-Plus/data/VPC/multiscale_...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862605</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/user01/MS-RGCN-Plus/data/VPC/multiscale_...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  n_experts_used  \\\n",
       "0  /home/user01/MS-RGCN-Plus/data/VPC/multiscale_...               4   \n",
       "1  /home/user01/MS-RGCN-Plus/data/VPC/multiscale_...               4   \n",
       "2  /home/user01/MS-RGCN-Plus/data/VPC/multiscale_...               4   \n",
       "3  /home/user01/MS-RGCN-Plus/data/VPC/multiscale_...               4   \n",
       "4  /home/user01/MS-RGCN-Plus/data/VPC/multiscale_...               4   \n",
       "\n",
       "   hard_label   p0   p1        p2   p3        p4   p5  \n",
       "0           4  0.0  0.0  0.000000  0.0  1.000000  0.0  \n",
       "1           4  0.0  0.0  0.000000  0.0  1.000000  0.0  \n",
       "2           4  0.0  0.0  0.067184  0.0  0.932816  0.0  \n",
       "3           4  0.0  0.0  0.137395  0.0  0.862605  0.0  \n",
       "4           4  0.0  0.0  0.128264  0.0  0.871736  0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV you just generated\n",
    "csv_path = \"/home/user01/MS-RGCN-Plus/data/VPC/patch_labels_majority.csv\"\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Show first few rows and shape\n",
    "df_shape = df.shape\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5396e974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hard_label\n",
       "4    13175\n",
       "2     5693\n",
       "1     3651\n",
       "0     1060\n",
       "3      169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hard_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf832a7",
   "metadata": {},
   "source": [
    "### Patch & Majority‑Vote Mask Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a62446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# ---- discrete colors for classes 0..5 (edit if you like)\n",
    "# 0: Benign, 1: G3, 2: G4, 3: G5, 4: (unused in paper), 5: (unused)  <-- adjust to your scheme if needed\n",
    "CLASS_NAMES = {0: \"0/Benign\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\"}\n",
    "PALETTE = np.array([\n",
    "    [  0, 170,   0],  # 0\n",
    "    [ 30, 144, 255],  # 1\n",
    "    [255, 140,   0],  # 2\n",
    "    [220,  20,  60],  # 3\n",
    "    [148,   0, 211],  # 4\n",
    "    [128, 128, 128],  # 5\n",
    "], dtype=np.uint8)\n",
    "\n",
    "cmap = ListedColormap(PALETTE / 255.0)\n",
    "norm = BoundaryNorm(list(range(7)), cmap.N)  # bins [0..6)\n",
    "\n",
    "def _majority_vote_crop(expert_mask_paths, x, y):\n",
    "    \"\"\"Return per-pixel majority-vote mask over experts for this patch window.\n",
    "       Pixels with no votes stay 255 (ignored). Ties -> higher class id.\"\"\"\n",
    "    H = W = PATCH_SIZE\n",
    "    counts = np.zeros((NUM_CLASSES, H, W), dtype=np.uint16)\n",
    "    any_vote = np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    for mp in expert_mask_paths:\n",
    "        m = io.imread(str(mp))\n",
    "        m = mask_to_ids(m)\n",
    "        crop = m[y:y+H, x:x+W]\n",
    "        if crop.shape[:2] != (H, W):\n",
    "            continue\n",
    "        for c in range(NUM_CLASSES):\n",
    "            votes = (crop == c)\n",
    "            counts[c] += votes\n",
    "            any_vote |= votes\n",
    "\n",
    "    if not any_vote.any():\n",
    "        return None  # no label coverage for this window\n",
    "\n",
    "    # argmax across classes; for ties, take the highest class id\n",
    "    # trick: add tiny class-index-based epsilon so ties prefer higher\n",
    "    eps = np.arange(NUM_CLASSES, dtype=np.float32)[:, None, None] * 1e-6\n",
    "    maj = np.argmax(counts.astype(np.float32) + eps, axis=0).astype(np.uint8)\n",
    "\n",
    "    # mark pixels with no votes as 255 (ignored)\n",
    "    maj[~any_vote] = 255\n",
    "    return maj\n",
    "\n",
    "def _colorize_mask(mask_uint8):\n",
    "    \"\"\"map class ids to RGB; 255 -> transparent mask\"\"\"\n",
    "    H, W = mask_uint8.shape\n",
    "    rgb = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    valid = mask_uint8 != 255\n",
    "    rgb[valid] = PALETTE[mask_uint8[valid]]\n",
    "    return rgb, valid\n",
    "\n",
    "def visualize_patch_with_vote(patch_path, alpha=0.45, show_probs=True):\n",
    "    \"\"\"Show: image, majority-vote mask, and overlay. Prints patch-level probs too.\"\"\"\n",
    "    patch_img = io.imread(patch_path)\n",
    "    scid = slide_core_id_from_path(patch_path)\n",
    "    x, y = coords_from_name(os.path.basename(patch_path))\n",
    "    expert_masks = find_annotator_masks_for_core(scid)\n",
    "\n",
    "    if len(expert_masks) == 0:\n",
    "        print(f\"[WARN] No expert masks found for {scid}\")\n",
    "        return\n",
    "\n",
    "    vote = _majority_vote_crop(expert_masks, x, y)\n",
    "    probs, hard, used = patch_label_probs_from_maps(patch_path)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(patch_img)\n",
    "    axs[0].set_title(\"Patch\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    if vote is None:\n",
    "        axs[1].text(0.5, 0.5, \"No label coverage\\nfor this window\", ha='center', va='center', fontsize=12)\n",
    "        axs[1].axis('off')\n",
    "        axs[2].imshow(patch_img)\n",
    "        axs[2].axis('off')\n",
    "    else:\n",
    "        axs[1].imshow(vote, cmap=cmap, norm=norm, vmin=0, vmax=5)\n",
    "        axs[1].set_title(\"Majority‑vote mask\")\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        color_mask, valid = _colorize_mask(vote)\n",
    "        # build RGBA overlay where valid=1 has alpha, others 0\n",
    "        overlay = np.dstack([color_mask, (valid.astype(np.float32) * alpha * 255).astype(np.uint8)])\n",
    "        axs[2].imshow(patch_img)\n",
    "        axs[2].imshow(overlay)\n",
    "        axs[2].set_title(\"Overlay\")\n",
    "        axs[2].axis('off')\n",
    "\n",
    "    # simple legend\n",
    "    handles = []\n",
    "    import matplotlib.patches as mpatches\n",
    "    for cid, name in CLASS_NAMES.items():\n",
    "        swatch = mpatches.Patch(color=PALETTE[cid]/255.0, label=f\"{cid}: {name}\")\n",
    "        handles.append(swatch)\n",
    "    fig.legend(handles=handles, loc=\"lower center\", ncol=min(6, len(handles)), bbox_to_anchor=(0.5, -0.02))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if show_probs and probs is not None:\n",
    "        print(f\"Experts used: {used}   Hard label: {hard}\")\n",
    "        for c, p in enumerate(probs):\n",
    "            print(f\"  p[{c}] = {p:.3f}\")\n",
    "    elif show_probs:\n",
    "        print(\"No per‑patch probabilities (no valid expert crops).\")\n",
    "\n",
    "# ---- Example usage: pick a patch and visualize\n",
    "# p = next(iter_patches(PATCH_ROOT, mags=(40,)))   # e.g., only 40×\n",
    "# visualize_patch_with_vote(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msrgcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
